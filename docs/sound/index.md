---
title: Sound
layout: layouts/compform_chapter.pug
debug: false

header_title: "Comp Sound"
next:
next_url:
previous: Generating Text
previous_url: ../text

hero_title: Comp Sound

description: Make some noise using the p5 sound library.
software: p5.js
---

## Sound

### p5.js Sound Library

In addition to the basic drawing API, p5.js includes add-on [libraries](https://p5js.org/libraries/). The [parameters](../parameters) chapter introduces the p5.dom library, and the examples in this chapter use the p5.sound library. The p5.sound library builds on the [Web Audio](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API) API and provides functions for generating tones, playing recorded sounds, and visualizing the waveform and spectrum of sounds. I highly suggest taking a look at **all** of the sound examples to get an idea of what the sound library can do.

This chapter will focus on playing and visualizing pre-recorded sound assets. The [comp music](../music) chapter talks more about sound synthesis.

- [p5.sound API Reference](https://p5js.org/reference/#/libraries/p5.sound)
- [p5.sound Examples](https://p5js.org/examples/)

::: .discussion

## Drawings and Sounds

Compare a basic p5.js drawing with a p5.audio sketch. What do they have in common? How are they different?

### Hello, p5.js!

```javascript
let myImg;

function preload() {
  myImg = loadImage("images/world.jpg");
}

function setup() {
  createCanvas(500, 500);
}

function draw() {
  image(myImg, 0, 0);
}
```

### Hello, p5.sound!

```javascript
let mySound;

function preload() {
  mySound = loadSound("sounds/hack-comp.wav");
}

function setup() {
  mySound.loop(0, 1, 1, 0, 4);
}
```

/::

### Computers, Light, Sound, and People

Light and sound flow through our environment as electromagnetic and air pressure waves. Our eyes and our ears collect data about these waves and our visual and auditory cortexes process that data to create information. Though they work in different ways, both of these sensory systems are powerful. We can take advantage of these systems by choosing the types of forms we create.

<!--[[This last sentence is unclear to me...I'll work on it.]]-->

[Light and Sound Lecture Notes](./light_and_sound.html)

## Playing Sound with p5.js

<!--
### Hello, Sound!

::: js-lab
/sound/sketches/hello_sound.js
/::

### Changing the Frequency

::: js-lab
/sound/sketches/oscillator.js
/::

### Modulating the Frequency

::: js-lab
/sound/sketches/modulator.js
/:: -->

### Playing Recorded Sounds

p5.js makes it pretty easy to play sound assets, like this audio clip from [Hackers(1995)](http://www.imdb.com/title/tt0113243/).

::: js-lab
/sound/sketches/hello_play.js
/::

::: .callout .warn
Chrome won't start playing sound on a page until the user performs a "gesture" on that page.

[Web Audio Autoplay Policy](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)

/::

### Changing Rate + Pitch

The third parameter to `play()` controlls the rate of playback. If you play a sound faster the pitch will go up; play it slower and the pitch will go down. p5 cannot change the pitch of a sound without changing its length.

::: js-lab
/sound/sketches/hello_pitch.js
/::

### Looping

::: js-lab
/sound/sketches/two_loops.js
/::

### Drum Kit

This example uses `frameCount` to keep time and play a beat with drum samples. This works for a quick sketch, but `frameCount` isn't a great timekeeping source, so you might notice hitches in your rhythm. The [Tone.js](https://tonejs.github.io) lets you precisely schedule when samples are played, and might be a better choice if you want to make music.

::: js-lab
/sound/sketches/hello_drum.js
/::

### Bounce

This example doesn't have any sound in it... yet.
::: js-lab
/sound/sketches/bounce.js
/::

## Capturing Output

p5.sound provides methods for recording the sound generated by your program and saving it to a file. The following function records `length` milliseconds of audio and saves it as `output.wav`.

Your audio may sound fine at run time but clipped when you play back the `.wav`. If this happens, try reducing the volume of the sounds you generate.

If you can't get good quality audio capture from p5.SoundRecorder, you might get better results using a screen recording program like Quicktime Player.

```javascript
// uses the p5 SoundRecorder and SoundFile classes to record the audio output.
// begins recording when called. records for _length_ time in milliseconds.
function record(length) {
  var soundRecorder = new p5.SoundRecorder();
  var soundFile = new p5.SoundFile();
  soundRecorder.record(soundFile);
  setTimeout(function() {
    console.log("Recording Complete");
    soundRecorder.stop();
    save(soundFile, "output.wav");
  }, length);
}
```

::: .activity

## In-class Challenge

- In the Drum Kit example, switch the samples used to play the beat.
- Change the timing to create a more complex beat.
- In the Bounce example, add a drum sound when the ball bounces.
- Add a little randomness to the playback rate of the sound each time the ball bounces. This little trick can add some realism to sound effects.

/::

## Visualizing Sound with p5.js

### Cuepoints

::: js-lab
/sound/sketches/hello_cue.js
/::

### Volume

::: js-lab
/sound/sketches/volume.js
/::

### Wave

::: js-lab
/sound/sketches/wave.js
/::

### FFT

The Fast Fourier Transform transform a signal from the time domain to the frequency domain. For audio analysis that means the FFT can tell the strenght of different frequencies in an audio buffer.

For a visual exploration of FFT, see this excelent video by 3Blue1Brown [But what is the Fourier Transform? A visual introduction.](https://www.youtube.com/watch?v=spUNpyF58BY)

::: js-lab
/sound/sketches/fft.js
/::

::: .activity

## In-class Challenge

- In the Cuepoints example, and a second cue that calls cueBig when the word "computers" is spoken.

- Change the Volume example so that the circle is centered and grows and shrinks to show the volume.

- Read the [p5.fft documentation](https://p5js.org/reference/#/p5.FFT), then experiment in the FFT example. Try chaning the params passed to `new p5.FFT()` one at a time and observe the changes.

- Study the code in the Making Sounds from Scratch example. Try to understand every line: look up anything you are unfamilliar with. When you start to understand, try commenting out the sin wave code and commenting in click, noise, and retro future. See what they do.



/::

<!-- ::: .activity

## In-class Challenge

Display a little melody.

/:: -->

### Making Sounds from Scratch

You can create an empty soundFile object with `new p5.SoundFile()` and generate the sound data yourself with Javascript. To do so you will create and fill a [Float32Array](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array) and then attach it to the SoundFile object with `setBuffer()`.

::: js-lab
/sound/sketches/buffer.js
/::

Creating sounds this way lets you work at the lowest possible level: individual samples. This can be fun, and it gives you complete control, but you will probably need to reinvent some basics.

P5.js has functions for working with oscillators, envelopes, and effects if you want to work at a little higher level. You might also consider using a dedicated Javascript sound synthesis library like [Tone.js](https://tonejs.github.io), which is a little more powerful and better documented.

::: .assignment

## Sketch!

### Base

Keep sketching. Make a bunch of noise!

### Challenge 1: Synesthesia 1

Choose a 15 second video clip. Use p5.sound to create a new soundtrack for your clip. Combine audio and sound and post.

### Challenge 2: Synesthesia 2

Choose a 15 second audio clip. Use p5.sound to generate graphics driven by the sound. Combine audio and sound and post.

### Challenge 3: Synesthesia 3

Create a 15 second procedurally generated audio+visual form. Create the audio and the video from the same process.

/::

## Reference Links

[Jamie Wong: Color from Hexcodes to Eyeballs](http://jamie-wong.com/post/color/)
: Jamie Wong describes the each step of how color is expressed and interpreted.

[Compform '16 Comp Music Notes](http://psam3060-d-s16.github.io/class_notes/week_9/)
: Compform '16 week on computational music.

[Compform '16 Comp Music Notes](http://psam3060-d-s16.github.io/class_notes/week_9/docco_out/)
: Examples from Compform '16 week on computational music.

[WebMidiAPIShim](https://github.com/cwilso/WebMIDIAPIShim)
: A javascript shim for accessing midi devices.

[3Blue1Brown: Fourier Transform](https://www.youtube.com/watch?v=spUNpyF58BY)
: A great visual introduction to the Fourier transform.

[An Interactive Introduction to Fourier Transforms](http://www.jezzamon.com/fourier/index.html)
: Visual and interactive demos of Fourier Transforms for both sound and drawing.
